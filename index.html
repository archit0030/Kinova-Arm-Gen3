<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Enhanced Robotic Task Automation</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            line-height: 1.6;
        }
        header {
            text-align: center;
            margin-bottom: 40px;
        }
        header h1 {
            font-size: 2.5em;
            margin-bottom: 0.2em;
        }
        section {
            margin-bottom: 20px;
        }
        section h2 {
            font-size: 1.8em;
            color: #333;
            margin-bottom: 10px;
        }
        section p {
            margin: 10px 0;
        }
        footer {
            text-align: center;
            margin-top: 40px;
            font-size: 0.9em;
            color: #666;
        }
        .video-container {
            text-align: center;
        }
        .video-container video {
            max-width: 100%;
            height: auto;
        }
    </style>
</head>
<body>

    <header>
        <h1>Enhanced Robotic Task Automation through Detailed Sub-action Recognition and Object-Aware Execution</h1>
        <p>Exploring advancements in robotic automation through smaller language models and object-aware execution</p>
    </header>

    <section>
        <h2>Introduction</h2>
        <p>We are excited to introduce our innovative approach to enhancing robotic systems with a tailored language model designed for precision and flexibility. While advanced language models like GPT-4 and Llama2 offer impressive capabilities in natural language understanding and reasoning, they often come with limitations such as high costs and dependency on continuous internet access. Our solution addresses these challenges by creating a customized, smaller language model (SLM) that extracts and executes key sub-actions from human commands with remarkable efficiency. By focusing on discrete, object-aware sub-actions, our model enhances robotic systems' ability to handle complex tasks with greater accuracy. We utilize a two-stage framework combining a large language model for sub-action extraction and a custom BiLSTM-MHAE model for implementation, making it possible for robots to perform intricate tasks without relying on heavy external dependencies. Explore our repository to see how this cutting-edge approach can elevate the capabilities of robotic systems.</p>
    </section>

    <!-- YouTube Video Section -->
    <div class="video-container">
        <h2>Demonstration Video</h2>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/kF7Yb7aYDKs?si=ELU-muSmt7oBDBrG&amp;start=5" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        <p>Watch this video to see the robotic task automation in action.</p>
    </div>

    <!-- GitHub-hosted Video Section -->
    <div class="video-container">
        <h2>GitHub-Hosted Video Demonstration</h2>
        <video width="600" controls>
            <source src="https://raw.githubusercontent.com/archit0030/SubActionRobot/main/videos/Pick%20and%20Stack.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        <p>Watch this video for a GitHub-hosted demonstration of the robotic task automation.</p>
    </div>


    <footer>
        <p>&copy; 2024 Enhanced Robotic Task Automation | Powered by GitHub Pages</p>
    </footer>

</body>
</html>
